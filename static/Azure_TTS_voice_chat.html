<!DOCTYPE html>
<html>
<head>
  <title>🎤 Voice Chat with Azure GPT-4o + Neural TTS</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; line-height: 1.6; }
    button { font-size: 16px; margin: 5px; padding: 10px; }
    #userText, #botResponse { font-weight: bold; }
    #log { margin-top: 20px; background: #f4f4f4; padding: 10px; border: 1px solid #ccc; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>🎤 Voice Chat with Azure GPT-4o + Azure Neural TTS</h2>
  <button id="start">🎙️ Start Speaking</button>
  <button id="stop">🚫 Stop Talking</button>
  <p><strong>You said:</strong> <span id="userText">...</span></p>
  <p><strong>Response:</strong> <span id="botResponse">...</span></p>
  <div id="log"><strong>Debug Log:</strong>\n</div>

  <script>
    const backendUrl = "https://copilot-voice-api-d8cue9bah3ezaegb.centralus-01.azurewebsites.net";
    const subscriptionKey = "CvfyBJcFIkwFoTa7OS23Rcbmp8s1Z8kuunMmoff7YC3GTKHo4MzGJQQJ99BFACHYHv6XJ3w3AAAYACOGIfBa";
    const ttsVoice = "en-US-AndrewMultilingualNeural";

    const startBtn = document.getElementById("start");
    const stopBtn = document.getElementById("stop");
    const userTextSpan = document.getElementById("userText");
    const botResponseSpan = document.getElementById("botResponse");
    const logDiv = document.getElementById("log");

    let audio = null;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.continuous = false;

    function log(msg) {
      logDiv.textContent += `\n${msg}`;
    }

    startBtn.onclick = () => {
      if (audio) {
        audio.pause();
        audio.currentTime = 0;
      }
      recognition.start();
      log("🎙️ Speech recognition started...");
    };

    stopBtn.onclick = () => {
      if (audio) {
        audio.pause();
        audio.currentTime = 0;
        log("⛔ Playback manually stopped.");
      }
    };

    recognition.onresult = async (event) => {
      const text = event.results[0][0].transcript;
      userTextSpan.textContent = text;
      log("✅ Recognized speech: " + text);

      try {
        const chatResponse = await fetch(`${backendUrl}/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text })
        });

        const data = await chatResponse.json();
        const reply = data.response || "No response from server.";
        botResponseSpan.textContent = reply;
        log("🤖 Received reply: " + reply);

        log("🔊 Speaking reply with TTS...");
        const ssml = `
          <speak version='1.0' xml:lang='en-US'>
            <voice xml:lang='en-US' xml:gender='Male' name='${ttsVoice}'>
              ${reply.replace(/[#*]+/g, "")}
            </voice>
          </speak>`;

        const ttsResponse = await fetch(`${backendUrl}/speak`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ text: ssml })
        });

        const ttsBlob = await ttsResponse.blob();
        audio = new Audio(URL.createObjectURL(ttsBlob));
        audio.play();

      } catch (error) {
        botResponseSpan.textContent = "Error occurred.";
        log("❌ Error: " + error.message);
      }
    };

    recognition.onerror = (e) => log("⚠️ Speech recognition error: " + e.error);
  </script>
</body>
</html>
