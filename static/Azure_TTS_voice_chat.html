<!DOCTYPE html>
<html>
<head>
  <title>Voice Chat Assistant</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; }
    button { font-size: 16px; margin: 5px; }
    #userText, #botResponse { font-weight: bold; }
    #log { margin-top: 20px; background: #f9f9f9; padding: 10px; border: 1px solid #ccc; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>üé§ Voice Chat with Azure GPT-4o + Azure Neural TTS</h2>
  <button id="start">Start Speaking</button>
  <button id="cancelSpeech">üö´ Stop Talking</button>
  <p><strong>You said:</strong> <span id="userText">...</span></p>
  <p><strong>Response:</strong> <span id="botResponse">...</span></p>
  <div id="log"><strong>Debug Log:</strong>\n</div>

 <script>
  const startBtn = document.getElementById("start");
  const cancelBtn = document.getElementById("cancelSpeech");
  const userTextSpan = document.getElementById("userText");
  const botResponseSpan = document.getElementById("botResponse");
  const logDiv = document.getElementById("log");

  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  const recognition = new SpeechRecognition();
  recognition.lang = "en-US";
  recognition.interimResults = false;
  recognition.continuous = false;

  let isSpeaking = false;
  let audio = null;

  function log(msg) {
    logDiv.textContent += `\n${msg}`;
  }

  function stopSpeaking() {
    if (audio) {
      audio.pause();
      audio.currentTime = 0;
      audio = null;
      isSpeaking = false;
      log("üîá Speech playback stopped.");
    }
  }

  async function speakText(reply) {
    log("üó£Ô∏è Speaking reply with TTS...");
    stopSpeaking();

    const ttsResponse = await fetch("https://eastus2.tts.speech.microsoft.com/cognitiveservices/v1", {
      method: "POST",
      headers: {
        "Ocp-Apim-Subscription-Key": "CvfyBJcFIkwFoTa7OS23Rcbmp8s1Z8kuunMmoff7YC3GTKHo4MzGJQQJ99BFACHYHv6XJ3w3AAAYACOGIfBa",
        "Content-Type": "application/ssml+xml",
        "X-Microsoft-OutputFormat": "audio-16khz-32kbitrate-mono-mp3"
      },
      body: `<speak version='1.0' xml:lang='en-US'>
               <voice name='en-US-AndrewMultilingualNeural'>${reply}</voice>
             </speak>`
    });

    const ttsBlob = await ttsResponse.blob();
    const audioUrl = URL.createObjectURL(ttsBlob);
    audio = new Audio(audioUrl);
    isSpeaking = true;

    audio.onended = () => {
      isSpeaking = false;
      log("üîÅ Restarting recognition...");
      recognition.start();
    };

    audio.play();
  }

  // Interruption: User starts speaking while assistant is talking
  recognition.onaudiostart = () => {
    if (isSpeaking) {
      stopSpeaking();
      log("üõë Interrupted speaking to listen.");
    }
  };

  startBtn.onclick = () => {
    stopSpeaking(); // Ensure no overlap
    recognition.start();
    log("üéôÔ∏è Speech recognition started...");
  };

  cancelBtn.onclick = () => {
    stopSpeaking();
    recognition.abort();
    log("üö´ Manual stop clicked.");
  };

  recognition.onresult = async (event) => {
    const text = event.results[0][0].transcript;
    userTextSpan.textContent = text;
    log(`‚úÖ Recognized speech: ${text}`);

    try {
      const response = await fetch("https://copilot-voice-api.azurewebsites.net/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ message: text })
      });

      const data = await response.json();
      const reply = data.response || "No response from server.";
      botResponseSpan.textContent = reply;
      await speakText(reply);

    } catch (error) {
      log("‚ùå Error: " + error.message);
      botResponseSpan.textContent = "Error occurred.";
      recognition.start(); // Try again
    }
  };

  recognition.onerror = (e) => {
    log("‚ö†Ô∏è Speech recognition error: " + e.error);
    if (!isSpeaking) recognition.start(); // Retry if not speaking
  };
</script>

 
</body>
</html>
