<!DOCTYPE html>
<html>
<head>
  <title>Voice Chat with Azure GPT-4o + Azure TTS</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; }
    button { font-size: 16px; margin: 5px; }
    #userText, #botResponse { font-weight: bold; }
    #log { margin-top: 20px; background: #f9f9f9; padding: 10px; border: 1px solid #ccc; white-space: pre-wrap; height: 150px; overflow-y: auto; }
    #micIndicator { display: inline-block; width: 10px; height: 10px; margin-left: 10px; border-radius: 50%; background: gray; animation: none; }
    #micIndicator.listening { background: red; animation: blink 1s infinite; }
    @keyframes blink {
      50% { opacity: 0.2; }
    }
  </style>
</head>
<body>
  <h2>ðŸŽ¤ Voice Chat with Azure GPT-4o + Azure Neural TTS</h2>
  <button id="start">Start Speaking</button>
  <button id="cancelSpeech">ðŸ›‘ Stop Talking</button>
  <label for="voiceSelect">ðŸ”Š Voice:</label>
  <select id="voiceSelect">
    <option value="en-US-AndrewMultilingualNeural">Andrew</option>
    <option value="en-US-JennyNeural">Jenny</option>
  </select>
  <span id="micIndicator" title="Mic status"></span>

  <p><strong>You said:</strong> <span id="userText">...</span></p>
  <p><strong>Response:</strong> <span id="botResponse">...</span></p>
  <div id="log"><strong>Debug Log:</strong>\n</div>

  <script>
    const startBtn = document.getElementById("start");
    const cancelBtn = document.getElementById("cancelSpeech");
    const userTextSpan = document.getElementById("userText");
    const botResponseSpan = document.getElementById("botResponse");
    const logDiv = document.getElementById("log");
    const voiceSelect = document.getElementById("voiceSelect");
    const micIndicator = document.getElementById("micIndicator");

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.continuous = true;

    let isListening = false;

    function log(msg) {
      logDiv.textContent += `\n${msg}`;
      logDiv.scrollTop = logDiv.scrollHeight;
    }

    function cleanTextForTTS(text) {
      return text
        .replace(/[#*_`~>-]/g, '')
        .replace(/\n+/g, ' ')
        .replace(/\s+/g, ' ')
        .trim();
    }

    startBtn.onclick = () => {
      if (!isListening) {
        recognition.start();
        isListening = true;
        micIndicator.classList.add("listening");
        log("ðŸŽ™ï¸ Speech recognition started...");
      }
    };

    cancelBtn.onclick = () => {
      recognition.stop();
      window.speechSynthesis.cancel();
      isListening = false;
      micIndicator.classList.remove("listening");
      log("ðŸ›‘ Speech recognition and synthesis stopped.");
    };

    recognition.onresult = async (event) => {
      const text = event.results[0][0].transcript;
      userTextSpan.textContent = text;
      log("Recognized speech: " + text);
      window.speechSynthesis.cancel();

      try {
        const response = await fetch("https://copilot-voice-api.azurewebsites.net/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text })
        });

        const data = await response.json();
        log("ðŸ§  GPT response: " + JSON.stringify(data));

        const reply = data.response || "No response from server.";
        const cleaned = cleanTextForTTS(reply);
        botResponseSpan.textContent = cleaned;

        const selectedVoice = voiceSelect.value;

        const ttsResponse = await fetch("https://eastus2.tts.speech.microsoft.com/cognitiveservices/v1", {
          method: "POST",
          headers: {
            "Ocp-Apim-Subscription-Key": "CvfyBJcFIkwFoTa7OS23Rcbmp8s1Z8kuunMmoff7YC3GTKHo4MzGJQQJ99BFACHYHv6XJ3w3AAAYACOGIfBa",
            "Content-Type": "application/ssml+xml",
            "X-Microsoft-OutputFormat": "audio-16khz-32kbitrate-mono-mp3"
          },
          body: `<speak version='1.0' xml:lang='en-US'>
                   <voice xml:lang='en-US' name='${selectedVoice}'>${cleaned}</voice>
                 </speak>`
        });

        const ttsBlob = await ttsResponse.blob();
        const audioUrl = URL.createObjectURL(ttsBlob);
        const audio = new Audio(audioUrl);
        audio.play();

      } catch (error) {
        log("âŒ Error: " + error.message);
        botResponseSpan.textContent = "Error occurred.";
      }
    };

    recognition.onerror = (e) => {
      log("âš ï¸ Speech recognition error: " + e.error);
    };

    recognition.onend = () => {
      if (isListening) {
        log("ðŸ”„ Recognition ended, restarting...");
        recognition.start();
      }
    };
  </script>
</body>
</html>