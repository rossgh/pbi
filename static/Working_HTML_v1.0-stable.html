<!DOCTYPE html>
<html>
<head>
  <title>Voice Chat with Azure GPT-4o + Neural TTS</title>
  <style>
    body { font-family: Arial, sans-serif; padding: 20px; background-color: #f0f4f8; }
    button { font-size: 16px; padding: 12px 20px; margin: 10px; }
    select { font-size: 16px; }
    #userText, #botResponse { font-weight: bold; margin-top: 15px; }
    #log { font-size: 12px; margin-top: 20px; background: #fff; padding: 10px; border: 1px solid #ccc; white-space: pre-wrap; }
  </style>
</head>
<body>
  <h2>üé§ Voice Chat with Azure GPT-4o + Neural TTS</h2>
  <button id="start">Start Speaking</button>
  <button id="stop">Stop Talking</button>
  <select id="voiceSelect">
    <option value="en-US-AndrewMultilingualNeural" selected>Andrew</option>
    <option value="en-US-JennyNeural">Jenny</option>
    <option value="en-GB-RyanNeural">Ryan</option>
    <option value="en-AU-NatashaNeural">Natasha</option>
  </select>
  <p id="userText">You said: ...</p>
  <p id="botResponse">Response: ...</p>
  <div id="log"><strong>Debug Log:</strong>\n</div>

  <script>
    const backendUrl = "https://copilot-voice-api-d8cue9bah3ezaegb.centralus-01.azurewebsites.net";
    const startBtn = document.getElementById("start");
    const stopBtn = document.getElementById("stop");
    const userTextSpan = document.getElementById("userText");
    const botResponseSpan = document.getElementById("botResponse");
    const logDiv = document.getElementById("log");
    const voiceSelect = document.getElementById("voiceSelect");

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = "en-US";
    recognition.interimResults = false;
    recognition.continuous = false;

    let audio = null;

    function log(msg) {
      logDiv.textContent += `\n${msg}`;
    }

    startBtn.onclick = () => {
      recognition.start();
      log("üéôÔ∏è Speech recognition started...");
    };

    stopBtn.onclick = () => {
      if (audio) audio.pause();
      window.speechSynthesis.cancel();
      log("üõë Speech stopped.");
    };

    recognition.onresult = async (event) => {
      const text = event.results[0][0].transcript;
      userTextSpan.textContent = "You said: " + text;
      log("‚úÖ Recognized speech: " + text);

      try {
        const chatResponse = await fetch(`${backendUrl}/chat`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message: text })
        });

        const data = await chatResponse.json();
        const reply = data.response || "No response from server.";
        botResponseSpan.textContent = "Response: " + reply;
        log("ü§ñ Received reply: " + reply);

        const cleanText = reply.replace(/[\#\*]+/g, "");
        const voice = voiceSelect.value;
        const ssml = `
          <speak version='1.0' xml:lang='en-US'>
            <voice xml:lang='en-US' name='${voice}'>
              ${cleanText}
            </voice>
          </speak>`;

        const ttsResponse = await fetch(`${backendUrl}/speak?voice=${voice}`, {
          method: "POST",
          headers: { "Content-Type": "application/ssml+xml" },
          body: ssml
        });

        const blob = await ttsResponse.blob();
        audio = new Audio(URL.createObjectURL(blob));
        audio.play();

      } catch (error) {
        botResponseSpan.textContent = "Error occurred.";
        log("‚ùå Error: " + error.message);
      }
    };

    recognition.onerror = (e) => log("‚ö†Ô∏è Speech recognition error: " + e.error);
  </script>
</body>
</html>
